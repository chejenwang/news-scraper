name: Daily TASS News Scraper

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  scrape-news:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install Chrome
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee -a /etc/apt/sources.list.d/google.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
    
    - name: Install ChromeDriver
      run: |
        wget -O /tmp/chromedriver-linux64.zip https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.204/linux64/chromedriver-linux64.zip
        unzip /tmp/chromedriver-linux64.zip -d /tmp/
        sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run scraper
      run: python tass_scraper.py
    
    - name: Commit and push
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add data/
        git diff --quiet && git diff --staged --quiet || (git commit -m "ðŸ“° Auto update: $(date +'%Y-%m-%d %H:%M:%S')" && git push)
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

#### ðŸ“„ `requirements.txt`
```
selenium==4.16.0
beautifulsoup4==4.12.2
pandas==2.1.4
openpyxl==3.1.2
googletrans==4.0.0-rc1
deep-translator==1.11.4
requests==2.31.0
```

#### ðŸ“„ `.gitignore`
```
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
.vscode/
.idea/
.DS_Store
Thumbs.db
test_*.xlsx
test_*.json